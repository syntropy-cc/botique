# InstalaÃ§Ã£o de Embeddings para Template Selector

Este guia explica como instalar as dependÃªncias necessÃ¡rias para o sistema de seleÃ§Ã£o semÃ¢ntica de templates usando embeddings.

## ğŸ“‹ Requisitos

O arquivo `src/templates/selector.py` usa a biblioteca `sentence-transformers` para gerar embeddings semÃ¢nticos de alta qualidade. Sem essa biblioteca, o sistema usa um mÃ©todo de fallback baseado em palavras-chave.

## ğŸš€ InstalaÃ§Ã£o

### OpÃ§Ã£o 1: InstalaÃ§Ã£o Direta (Recomendado)

```bash
# No diretÃ³rio do projeto
cd /home/jescott/syntropy-cc/botique

# Instalar todas as dependÃªncias de embeddings
pip install -r requirements_templates.txt
```

### OpÃ§Ã£o 2: InstalaÃ§Ã£o MÃ­nima (Apenas sentence-transformers)

Se vocÃª quiser instalar apenas o essencial:

```bash
pip install sentence-transformers
```

O `sentence-transformers` instalarÃ¡ automaticamente suas dependÃªncias:
- `torch` (PyTorch)
- `transformers` (Hugging Face)
- `numpy`
- E outras dependÃªncias necessÃ¡rias

### OpÃ§Ã£o 3: Usando Ambiente Virtual (Recomendado para ProduÃ§Ã£o)

Para isolar as dependÃªncias e evitar conflitos:

```bash
# Criar ambiente virtual
python3 -m venv venv

# Ativar ambiente virtual
# No Linux/Mac:
source venv/bin/activate
# No Windows:
# venv\Scripts\activate

# Instalar dependÃªncias
pip install -r requirements_templates.txt
```

## âœ… VerificaÃ§Ã£o

ApÃ³s a instalaÃ§Ã£o, vocÃª pode verificar se estÃ¡ funcionando:

```python
from sentence_transformers import SentenceTransformer

# Testar carregamento do modelo padrÃ£o
model = SentenceTransformer('all-MiniLM-L6-v2')
print("âœ… Embeddings instalados e funcionando!")
```

Ou execute o seletor de templates:

```python
from src.templates.selector import TemplateSelector

selector = TemplateSelector()
# Se nÃ£o houver avisos sobre fallback, estÃ¡ funcionando!
```

## ğŸ“¦ DependÃªncias Instaladas

O arquivo `requirements_templates.txt` instala:

- **sentence-transformers** (>=2.2.0): Biblioteca principal para embeddings
- **torch** (>=1.9.0): PyTorch para modelos de deep learning
- **transformers** (>=4.20.0): Biblioteca Hugging Face para modelos
- **numpy** (>=1.19.0): OperaÃ§Ãµes numÃ©ricas

## ğŸ”§ Modelos DisponÃ­veis

O sistema usa por padrÃ£o o modelo `all-MiniLM-L6-v2`, que Ã©:
- âœ… RÃ¡pido e eficiente
- âœ… Otimizado para inglÃªs
- âœ… Pequeno (~80MB)

### Modelos Alternativos

VocÃª pode especificar outros modelos ao inicializar o `TemplateSelector`:

```python
# MultilÃ­ngue (mais lento, mas suporta portuguÃªs)
selector = TemplateSelector(model_name="paraphrase-multilingual-MiniLM-L12-v2")

# Maior qualidade (mais lento)
selector = TemplateSelector(model_name="all-mpnet-base-v2")

# PadrÃ£o (rÃ¡pido, inglÃªs)
selector = TemplateSelector(model_name="all-MiniLM-L6-v2")
```

## âš ï¸ SoluÃ§Ã£o de Problemas

### Erro de PermissÃ£o

Se vocÃª encontrar erros de permissÃ£o:

```bash
# Usar --user para instalar no diretÃ³rio do usuÃ¡rio
pip install --user -r requirements_templates.txt

# Ou usar sudo (nÃ£o recomendado)
sudo pip install -r requirements_templates.txt
```

### EspaÃ§o em Disco

Os modelos podem ocupar bastante espaÃ§o:
- `all-MiniLM-L6-v2`: ~80MB
- `paraphrase-multilingual-MiniLM-L12-v2`: ~420MB
- `all-mpnet-base-v2`: ~420MB

Certifique-se de ter pelo menos 500MB livres.

### Primeira ExecuÃ§Ã£o

Na primeira vez que vocÃª usar um modelo, ele serÃ¡ baixado automaticamente do Hugging Face. Isso pode levar alguns minutos dependendo da sua conexÃ£o.

## ğŸ“ Notas

- O sistema tem **fallback automÃ¡tico**: se `sentence-transformers` nÃ£o estiver disponÃ­vel, usa mÃ©todo baseado em palavras-chave
- Os embeddings sÃ£o **prÃ©-computados** na inicializaÃ§Ã£o para melhor performance
- O cache de embeddings Ã© mantido em memÃ³ria durante a execuÃ§Ã£o

## ğŸ”— ReferÃªncias

- [DocumentaÃ§Ã£o sentence-transformers](https://www.sbert.net/)
- [Modelos disponÃ­veis no Hugging Face](https://huggingface.co/models?library=sentence-transformers)
- [DocumentaÃ§Ã£o do Template Selector](./SEMANTIC_TEMPLATE_SELECTION.md)
